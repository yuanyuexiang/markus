#!/usr/bin/env python3
"""
ç­¾åéªŒè¯GNNè®­ç»ƒè„šæœ¬
ä½¿ç”¨å…³é”®ç‚¹æ ‡æ³¨æ•°æ®è®­ç»ƒå›¾ç¥ç»ç½‘ç»œ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.data import Data, DataLoader
from torch_geometric.nn import GCNConv, global_mean_pool
import json
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt


class SignatureGNN(nn.Module):
    """ç­¾åéªŒè¯å›¾ç¥ç»ç½‘ç»œ"""
    
    def __init__(self, input_dim=6, hidden_dim=64, output_dim=128):
        super(SignatureGNN, self).__init__()
        self.conv1 = GCNConv(input_dim, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, hidden_dim)
        self.conv3 = GCNConv(hidden_dim, output_dim)
        
    def forward(self, x, edge_index, batch):
        # å›¾å·ç§¯å±‚
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.2, training=self.training)
        
        x = self.conv2(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.2, training=self.training)
        
        x = self.conv3(x, edge_index)
        
        # å›¾çº§åˆ«çš„æ± åŒ–
        x = global_mean_pool(x, batch)
        
        return x


def load_keypoint_data(json_path):
    """åŠ è½½å…³é”®ç‚¹JSONæ•°æ®"""
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data


def extract_node_features(keypoints, width, height):
    """æå–èŠ‚ç‚¹ç‰¹å¾"""
    type_to_idx = {
        'endpoint': 0,
        'junction': 1,
        'corner': 2,
        'bifurcation': 3
    }
    
    features = []
    for kp in keypoints:
        # å½’ä¸€åŒ–ä½ç½®
        x_norm = kp['x'] / width
        y_norm = kp['y'] / height
        
        # one-hotç¼–ç ç±»å‹
        type_onehot = [0, 0, 0, 0]
        type_idx = type_to_idx.get(kp['type'], 0)
        type_onehot[type_idx] = 1
        
        feat = [x_norm, y_norm] + type_onehot
        features.append(feat)
    
    return torch.tensor(features, dtype=torch.float)


def compute_graph_edges(keypoints, max_distance=50):
    """è®¡ç®—å›¾çš„è¾¹"""
    edges = []
    n = len(keypoints)
    
    for i in range(n):
        for j in range(i+1, n):
            x1, y1 = keypoints[i]['x'], keypoints[i]['y']
            x2, y2 = keypoints[j]['x'], keypoints[j]['y']
            
            dist = np.sqrt((x1-x2)**2 + (y1-y2)**2)
            
            if dist <= max_distance:
                edges.append([i, j])
                edges.append([j, i])  # æ— å‘å›¾
    
    if not edges:
        # å¦‚æœæ²¡æœ‰è¾¹,è‡³å°‘åˆ›å»ºè‡ªç¯
        edges = [[i, i] for i in range(n)]
    
    return torch.tensor(edges, dtype=torch.long).t().contiguous()


def create_graph_from_json(json_path):
    """ä»JSONæ–‡ä»¶åˆ›å»ºPyGå›¾å¯¹è±¡"""
    data_dict = load_keypoint_data(json_path)
    
    keypoints = data_dict['keypoints']
    width = data_dict['image_size']['width']
    height = data_dict['image_size']['height']
    
    # æå–ç‰¹å¾å’Œè¾¹
    x = extract_node_features(keypoints, width, height)
    edge_index = compute_graph_edges(keypoints, max_distance=50)
    
    return Data(x=x, edge_index=edge_index)


def prepare_dataset():
    """å‡†å¤‡è®­ç»ƒæ•°æ®é›†"""
    print("=" * 60)
    print("ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®é›†")
    print("=" * 60)
    
    # æ”¶é›†æ‰€æœ‰JSONæ–‡ä»¶
    template_files = sorted(Path(".").glob("keypoints_template_*_auto.json"))
    query_files = sorted(Path(".").glob("keypoints_query_*_auto.json"))
    
    print(f"\næ‰¾åˆ°æ•°æ®æ–‡ä»¶:")
    print(f"  æ¨¡æ¿ç­¾å: {len(template_files)} ä¸ª")
    print(f"  æŸ¥è¯¢ç­¾å: {len(query_files)} ä¸ª")
    
    # åˆ›å»ºè®­ç»ƒæ ·æœ¬å¯¹
    # ç­–ç•¥: åŒä¸€æ‰¹æ¬¡çš„templateå’Œqueryè§†ä¸ºgenuine pair,ä¸åŒæ‰¹æ¬¡ä¸ºforged pair
    pairs = []
    labels = []
    
    # æå–æ—¶é—´æˆ³ä½œä¸ºæ‰¹æ¬¡æ ‡è¯†
    def get_timestamp(filepath):
        name = filepath.stem
        parts = name.split('_')
        # æ‰¾åˆ°ç±»ä¼¼20251029_124437çš„æ—¶é—´æˆ³
        for i, part in enumerate(parts):
            if len(part) == 8 and part.isdigit():
                if i+1 < len(parts) and len(parts[i+1]) == 6 and parts[i+1].isdigit():
                    return f"{part}_{parts[i+1]}"
        return None
    
    template_by_time = {}
    for tf in template_files:
        ts = get_timestamp(tf)
        if ts:
            template_by_time[ts] = tf
    
    query_by_time = {}
    for qf in query_files:
        ts = get_timestamp(qf)
        if ts:
            query_by_time[ts] = qf
    
    # åˆ›å»ºgenuine pairs (ç›¸åŒæ—¶é—´æˆ³)
    genuine_count = 0
    for ts in template_by_time.keys():
        if ts in query_by_time:
            pairs.append((template_by_time[ts], query_by_time[ts]))
            labels.append(1)  # genuine
            genuine_count += 1
    
    print(f"\nç”Ÿæˆè®­ç»ƒå¯¹:")
    print(f"  çœŸç­¾åå¯¹ (Genuine): {genuine_count}")
    
    # åˆ›å»ºforged pairs (ä¸åŒæ—¶é—´æˆ³)
    forged_count = 0
    timestamps = list(template_by_time.keys())
    for i, ts1 in enumerate(timestamps):
        for ts2 in timestamps[i+1:]:
            if forged_count < genuine_count:  # å¹³è¡¡æ•°æ®é›†
                pairs.append((template_by_time[ts1], query_by_time[ts2]))
                labels.append(0)  # forged
                forged_count += 1
    
    print(f"  å‡ç­¾åå¯¹ (Forged): {forged_count}")
    print(f"  æ€»è®¡: {len(pairs)} å¯¹")
    
    return pairs, labels


def train_siamese_gnn(pairs, labels, epochs=50):
    """è®­ç»ƒSiamese GNN"""
    print("\n" + "=" * 60)
    print("ğŸš€ å¼€å§‹è®­ç»ƒSiamese GNN")
    print("=" * 60)
    
    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    train_pairs, test_pairs, train_labels, test_labels = train_test_split(
        pairs, labels, test_size=0.2, random_state=42, stratify=labels
    )
    
    print(f"\næ•°æ®åˆ’åˆ†:")
    print(f"  è®­ç»ƒé›†: {len(train_pairs)} å¯¹")
    print(f"  æµ‹è¯•é›†: {len(test_pairs)} å¯¹")
    
    # åˆ›å»ºæ¨¡å‹
    model = SignatureGNN(input_dim=6, hidden_dim=64, output_dim=128)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    
    # è®­ç»ƒå†å²
    train_losses = []
    test_accs = []
    
    print(f"\nå¼€å§‹è®­ç»ƒ ({epochs} epochs)...")
    print("-" * 60)
    
    for epoch in range(epochs):
        model.train()
        total_loss = 0
        
        # è®­ç»ƒä¸€ä¸ªepoch
        for (template_path, query_path), label in zip(train_pairs, train_labels):
            optimizer.zero_grad()
            
            # åŠ è½½å›¾å¯¹
            graph1 = create_graph_from_json(template_path)
            graph2 = create_graph_from_json(query_path)
            
            # å‰å‘ä¼ æ’­
            batch1 = torch.zeros(graph1.x.size(0), dtype=torch.long)
            batch2 = torch.zeros(graph2.x.size(0), dtype=torch.long)
            
            emb1 = model(graph1.x, graph1.edge_index, batch1)
            emb2 = model(graph2.x, graph2.edge_index, batch2)
            
            # è®¡ç®—è·ç¦»
            distance = F.pairwise_distance(emb1, emb2)
            
            # Contrastive loss
            label_tensor = torch.tensor([label], dtype=torch.float)
            margin = 1.0
            
            if label == 1:  # genuine
                loss = distance ** 2
            else:  # forged
                loss = torch.clamp(margin - distance, min=0.0) ** 2
            
            loss = loss.mean()
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
        
        avg_loss = total_loss / len(train_pairs)
        train_losses.append(avg_loss)
        
        # æµ‹è¯•
        model.eval()
        correct = 0
        with torch.no_grad():
            for (template_path, query_path), label in zip(test_pairs, test_labels):
                graph1 = create_graph_from_json(template_path)
                graph2 = create_graph_from_json(query_path)
                
                batch1 = torch.zeros(graph1.x.size(0), dtype=torch.long)
                batch2 = torch.zeros(graph2.x.size(0), dtype=torch.long)
                
                emb1 = model(graph1.x, graph1.edge_index, batch1)
                emb2 = model(graph2.x, graph2.edge_index, batch2)
                
                distance = F.pairwise_distance(emb1, emb2).item()
                
                # é˜ˆå€¼åˆ¤æ–­
                threshold = 0.5
                pred = 1 if distance < threshold else 0
                
                if pred == label:
                    correct += 1
        
        test_acc = correct / len(test_pairs)
        test_accs.append(test_acc)
        
        if (epoch + 1) % 10 == 0:
            print(f"Epoch {epoch+1:3d}/{epochs} | Loss: {avg_loss:.4f} | Test Acc: {test_acc:.2%}")
    
    print("-" * 60)
    print(f"âœ… è®­ç»ƒå®Œæˆ!")
    print(f"   æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {test_accs[-1]:.2%}")
    
    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    plot_training_curves(train_losses, test_accs)
    
    # ä¿å­˜æ¨¡å‹
    torch.save(model.state_dict(), 'signature_gnn_model.pth')
    print(f"   æ¨¡å‹å·²ä¿å­˜: signature_gnn_model.pth")
    
    return model, test_accs[-1]


def plot_training_curves(train_losses, test_accs):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    
    # Lossæ›²çº¿
    ax1.plot(train_losses, 'b-', linewidth=2)
    ax1.set_xlabel('Epoch', fontsize=12)
    ax1.set_ylabel('Training Loss', fontsize=12)
    ax1.set_title('Training Loss Curve', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    
    # Accuracyæ›²çº¿
    ax2.plot([acc * 100 for acc in test_accs], 'g-', linewidth=2)
    ax2.set_xlabel('Epoch', fontsize=12)
    ax2.set_ylabel('Test Accuracy (%)', fontsize=12)
    ax2.set_title('Test Accuracy Curve', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('training_curves.png', dpi=150)
    print(f"   è®­ç»ƒæ›²çº¿å·²ä¿å­˜: training_curves.png")
    plt.close()


if __name__ == '__main__':
    print("\n" + "=" * 60)
    print("ğŸ“ ç­¾åéªŒè¯GNNè®­ç»ƒç³»ç»Ÿ")
    print("=" * 60)
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import torch_geometric
        print("âœ… PyTorch Geometric å·²å®‰è£…")
    except ImportError:
        print("âŒ éœ€è¦å®‰è£… PyTorch Geometric:")
        print("   pip install torch-geometric")
        print("   pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cpu.html")
        exit(1)
    
    # å‡†å¤‡æ•°æ®
    pairs, labels = prepare_dataset()
    
    if len(pairs) == 0:
        print("\nâŒ æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒæ•°æ®!")
        print("   è¯·ç¡®ä¿å·²è¿è¡Œè‡ªåŠ¨æ ‡æ³¨ç”ŸæˆJSONæ–‡ä»¶")
        exit(1)
    
    # è®­ç»ƒæ¨¡å‹
    model, final_acc = train_siamese_gnn(pairs, labels, epochs=50)
    
    print("\n" + "=" * 60)
    print("ğŸ‰ è®­ç»ƒå®Œæˆ!")
    print("=" * 60)
    print(f"\næœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {final_acc:.2%}")
    print(f"\nç”Ÿæˆæ–‡ä»¶:")
    print(f"  - signature_gnn_model.pth (æ¨¡å‹æƒé‡)")
    print(f"  - training_curves.png (è®­ç»ƒæ›²çº¿)")
    print("\nä¸‹ä¸€æ­¥:")
    print(f"  1. æŸ¥çœ‹è®­ç»ƒæ›²çº¿: open training_curves.png")
    print(f"  2. å¦‚æœå‡†ç¡®ç‡>85%, å¯ä»¥éƒ¨ç½²åˆ°åç«¯")
    print(f"  3. å¦‚æœå‡†ç¡®ç‡<85%, éœ€è¦æ›´å¤šè®­ç»ƒæ•°æ®æˆ–è°ƒæ•´è¶…å‚æ•°")
    print("=" * 60 + "\n")
