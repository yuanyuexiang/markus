"""
ç­¾åå›¾ç« éªŒè¯ç³»ç»Ÿ - åç«¯API
ç­¾å: SigNetä¸“ä¸šæ¨¡å‹
å°ç« : CLIPå›¾åƒç›¸ä¼¼åº¦
"""
from fastapi import FastAPI, File, UploadFile, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles
import clip
import torch
from PIL import Image
import io
import cv2
import numpy as np
from typing import Literal
import torch.nn.functional as F
import time
import os
from datetime import datetime


def _open_image_as_grayscale(upload_bytes: bytes) -> Image.Image:
    """Open an uploaded image and convert it to grayscale on a white background.

    This avoids transparency (RGBA) being treated as black when converting to 'L',
    which can heavily distort signature/seal similarity.
    """
    img = Image.open(io.BytesIO(upload_bytes))
    if img.mode in ("RGBA", "LA"):
        background = Image.new("RGBA", img.size, (255, 255, 255, 255))
        img = Image.alpha_composite(background, img.convert("RGBA")).convert("RGB")
    return img.convert("L")


def _open_image_as_rgb(upload_bytes: bytes) -> Image.Image:
    """Open an uploaded image and convert it to RGB on a white background."""
    img = Image.open(io.BytesIO(upload_bytes))
    if img.mode in ("RGBA", "LA"):
        background = Image.new("RGBA", img.size, (255, 255, 255, 255))
        img = Image.alpha_composite(background, img.convert("RGBA")).convert("RGB")
    else:
        img = img.convert("RGB")
    return img

app = FastAPI(title="ç­¾åå›¾ç« éªŒè¯ç³»ç»Ÿ")

# å…è®¸è·¨åŸŸ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
os.makedirs("uploaded_samples", exist_ok=True)
os.makedirs("uploads", exist_ok=True)
os.makedirs("models", exist_ok=True)

# æŒ‚è½½é™æ€æ–‡ä»¶æœåŠ¡ï¼Œç”¨äºè®¿é—®ä¸Šä¼ çš„æ ·æœ¬å’Œè°ƒè¯•å›¾ç‰‡
app.mount("/uploaded_samples", StaticFiles(directory="uploaded_samples"), name="uploaded_samples")

# å…¨å±€åŠ è½½CLIPæ¨¡å‹(å°ç« ä½¿ç”¨)
print("ğŸ”„ æ­£åœ¨åŠ è½½CLIPæ¨¡å‹...")
device = "cpu"
clip_model, clip_preprocess = clip.load("ViT-B/32", device=device)
print("âœ… CLIPæ¨¡å‹åŠ è½½å®Œæˆ")

# SigNetå»¶è¿ŸåŠ è½½(é¿å…TensorFlowå¯åŠ¨é˜»å¡)
signet_model = None
_signet_imports = {}

def load_signet_model():
    """å»¶è¿ŸåŠ è½½SigNetæ¨¡å‹(é¦–æ¬¡è°ƒç”¨æ—¶åŠ è½½)"""
    global signet_model, _signet_imports
    if signet_model is not None:
        return signet_model
    
    try:
        import sys

        # ç¡®ä¿ backend ç›®å½•åœ¨ sys.path ä¸­ï¼Œé¿å…åœ¨ä¸åŒå¯åŠ¨æ–¹å¼ä¸‹å¯¼å…¥å¤±è´¥
        backend_dir = os.path.dirname(os.path.abspath(__file__))
        if backend_dir not in sys.path:
            sys.path.insert(0, backend_dir)

        from signet_model import SigNetModel
        from preprocess.normalize import preprocess_signature
        _signet_imports['SigNetModel'] = SigNetModel
        _signet_imports['preprocess_signature'] = preprocess_signature

        # ä½¿ç”¨ backend ç›®å½•ä¸‹çš„ models è·¯å¾„ï¼Œé¿å…å—å½“å‰å·¥ä½œç›®å½•å½±å“
        model_path = os.path.join(backend_dir, 'models', 'signet.pkl')
        signet_model = SigNetModel(model_path)
        print("âœ… SigNetç­¾åéªŒè¯æ¨¡å‹åŠ è½½å®Œæˆ")
        return signet_model
    except Exception as e:
        print(f"âš ï¸ SigNetæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

def preprocess_for_feature_matching(img_cv: np.ndarray) -> np.ndarray:
    """
    å›¾åƒé¢„å¤„ç†ç”¨äºç‰¹å¾ç‚¹åŒ¹é…
    1. è‡ªé€‚åº”äºŒå€¼åŒ–ï¼šå»é™¤èƒŒæ™¯å™ªå£°
    2. å½¢æ€å­¦å¤„ç†ï¼šè¿æ¥æ–­ç‚¹ï¼Œå»é™¤å°å™ªç‚¹
    """
    # è‡ªé€‚åº”é˜ˆå€¼äºŒå€¼åŒ–ï¼ˆå¯¹ä¸å‡åŒ€å…‰ç…§æ›´é²æ£’ï¼‰
    binary = cv2.adaptiveThreshold(
        img_cv, 255, 
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY, 
        blockSize=11,  # é‚»åŸŸå¤§å°
        C=2  # å¸¸æ•°åç§»
    )
    
    # å½¢æ€å­¦é—­è¿ç®—ï¼šè¿æ¥æ–­å¼€çš„ç¬”ç”»
    kernel = np.ones((3, 3), np.uint8)
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
    
    # å»é™¤å°å™ªç‚¹
    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
    
    return binary

def normalize_and_resize(img: np.ndarray, target_size: int = None) -> np.ndarray:
    """
    æ™ºèƒ½æ ‡å‡†åŒ–ï¼šä¿æŒé•¿å®½æ¯”ï¼Œè‡ªé€‚åº”é€‰æ‹©ç›®æ ‡å°ºå¯¸
    - å°å›¾ç‰‡ï¼ˆ<300pxï¼‰ï¼šæ”¾å¤§åˆ°è‡³å°‘300px
    - å¤§å›¾ç‰‡ï¼ˆ>800pxï¼‰ï¼šç¼©å°åˆ°800pxä»¥å†…
    - ä¸­ç­‰å›¾ç‰‡ï¼šä¿æŒåŸæ ·
    """
    h, w = img.shape[:2]
    max_dim = max(h, w)
    
    # æ ¹æ®åŸå›¾å°ºå¯¸è‡ªé€‚åº”ç›®æ ‡å°ºå¯¸
    if target_size is None:
        if max_dim < 300:
            target_size = 300  # å°å›¾æ”¾å¤§
        elif max_dim > 800:
            target_size = 800  # å¤§å›¾ç¼©å°
        else:
            target_size = max_dim  # ä¸­ç­‰å›¾ä¿æŒ
    
    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
    scale = target_size / max_dim
    new_w = int(w * scale)
    new_h = int(h * scale)
    
    # ç­‰æ¯”ä¾‹ç¼©æ”¾
    if scale != 1.0:
        resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA if scale < 1 else cv2.INTER_CUBIC)
    else:
        resized = img.copy()
    
    # åˆ›å»ºæ­£æ–¹å½¢ç”»å¸ƒï¼ˆç™½è‰²èƒŒæ™¯ï¼‰
    canvas = np.ones((target_size, target_size), dtype=np.uint8) * 255
    
    # å°†ç¼©æ”¾åçš„å›¾ç‰‡å±…ä¸­æ”¾ç½®
    y_offset = (target_size - new_h) // 2
    x_offset = (target_size - new_w) // 2
    canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
    
    return canvas, scale

def compute_feature_similarity(img1: Image.Image, img2: Image.Image) -> float:
    """
    ç‰¹å¾ç‚¹åŒ¹é…å·²ç¦ç”¨ - åªä½¿ç”¨CLIP
    """
    return 0.0  # ä¸å†ä½¿ç”¨ç‰¹å¾ç‚¹åŒ¹é…

def compute_ssim_similarity(img1: np.ndarray, img2: np.ndarray) -> float:
    """è®¡ç®—ç»“æ„ç›¸ä¼¼åº¦ï¼ˆSSIMï¼‰ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ"""
    try:
        from skimage.metrics import structural_similarity as ssim
        score = ssim(img1, img2)
        return max(0.0, min(1.0, score))
    except:
        # å¦‚æœssimä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€å•çš„MSE
        mse = np.mean((img1.astype(float) - img2.astype(float)) ** 2)
        similarity = 1.0 / (1.0 + mse / 1000.0)
        return float(similarity)

def compute_signet_similarity(template_img, query_img, enable_clean=True, clean_mode='conservative'):
    """ä½¿ç”¨SigNetè®¡ç®—ç­¾åç›¸ä¼¼åº¦ï¼Œæ”¯æŒç­¾åæ¸…æ´åŠŸèƒ½
    
    Args:
        template_img: æ¨¡æ¿å›¾åƒ
        query_img: æŸ¥è¯¢å›¾åƒ
        enable_clean: æ˜¯å¦å¯ç”¨ç­¾åæ¸…æ´
        clean_mode: æ¸…æ´æ¨¡å¼ 'conservative'(ä¸­æ–‡) æˆ– 'aggressive'(è‹±æ–‡)
    
    Returns:
        åŒ…å«ç›¸ä¼¼åº¦ã€è·ç¦»ã€SSIMã€å¤„ç†æµç¨‹ä¿¡æ¯çš„å­—å…¸
    """
    model = load_signet_model()
    if model is None:
        return None
    
    try:
        preprocess_signature = _signet_imports['preprocess_signature']
        # å»¶è¿Ÿå¯¼å…¥å¢å¼ºé¢„å¤„ç†
        try:
            from preprocess.auto_crop import robust_preprocess, robust_preprocess_with_clean, clean_signature_with_morph
        except Exception as _e:
            robust_preprocess = None
            robust_preprocess_with_clean = None
            clean_signature_with_morph = None
        
        # è½¬æ¢PIL Imageåˆ°numpy array (ç°åº¦å›¾)
        template_np = np.array(template_img.convert('L'))
        query_np = np.array(query_img.convert('L'))
        
        # ä¿å­˜é«˜åˆ†è¾¨ç‡çš„æ¸…æ´å›¾ç‰‡ï¼ˆç”¨äºå‰ç«¯å±•ç¤ºï¼‰
        template_cleaned_display = None
        query_cleaned_display = None
        
        if enable_clean and clean_signature_with_morph is not None:
            # å¯¹åŸå§‹å›¾ç‰‡è¿›è¡Œæ¸…æ´ï¼Œä¿æŒåŸå§‹å°ºå¯¸
            template_cleaned_display = clean_signature_with_morph(template_np, mode=clean_mode)
            query_cleaned_display = clean_signature_with_morph(query_np, mode=clean_mode)
            # åè½¬ï¼ˆæ¸…æ´åæ˜¯å‰æ™¯255ï¼Œéœ€è¦è½¬æˆèƒŒæ™¯255ï¼‰
            template_cleaned_display = cv2.bitwise_not(template_cleaned_display)
            query_cleaned_display = cv2.bitwise_not(query_cleaned_display)
        
        # ä¼ ç»Ÿé¢„å¤„ç†è·¯å¾„ï¼ˆå›é€€ï¼‰
        fallback_template = preprocess_signature(template_np, canvas_size=(952, 1360))
        fallback_query = preprocess_signature(query_np, canvas_size=(952, 1360))

        # é€‰æ‹©å¢å¼ºé¢„å¤„ç†è·¯å¾„
        if enable_clean and robust_preprocess_with_clean is not None:
            # ä½¿ç”¨å¸¦æ¸…æ´çš„é¢„å¤„ç†
            t_auto = robust_preprocess_with_clean(template_np, clean_mode=clean_mode)
            q_auto = robust_preprocess_with_clean(query_np, clean_mode=clean_mode)
            pipeline_name = f'robust+clean({clean_mode})'
        elif robust_preprocess is not None:
            # ä½¿ç”¨æ— æ¸…æ´çš„é²æ£’é¢„å¤„ç†
            t_auto = robust_preprocess(template_np)
            q_auto = robust_preprocess(query_np)
            pipeline_name = 'robust'
        else:
            t_auto = q_auto = None
            pipeline_name = 'classical'

        auto_valid = (
            t_auto is not None and q_auto is not None and
            t_auto.shape == (150, 220) and q_auto.shape == (150, 220)
        )

        # è®¡ç®—ä¸¤æ¡è·¯å¾„çš„è·ç¦»
        dist_fallback = model.compute_similarity(fallback_template, fallback_query)
        dist_auto = None
        if auto_valid:
            dist_auto = model.compute_similarity(t_auto, q_auto)

        # é€‰æ‹©è·¯å¾„ï¼šå½“ä¸¤æ¡è·¯å¾„â€œæ˜æ˜¾ä¸ä¸€è‡´â€æ—¶ï¼Œé‡‡ç”¨æ›´ä¿å®ˆçš„è·ç¦»ï¼ˆæ›´å¤§ï¼‰æ¥é™ä½è¯¯é€šè¿‡
        if dist_auto is None:
            euclidean_dist = dist_fallback
            pipeline = 'classical'
            ssim_inputs = (fallback_template, fallback_query)
        else:
            delta = abs(dist_auto - dist_fallback)

            # å°å·®å¼‚ï¼šè®¤ä¸ºä¸¤æ¡è·¯å¾„ä¸€è‡´ï¼Œä½¿ç”¨æ›´å°è·ç¦»ï¼ˆæ›´ä¹è§‚ï¼Œå¬å›æ›´å¥½ï¼‰
            if delta <= 0.003:
                if dist_auto <= dist_fallback:
                    euclidean_dist = dist_auto
                    pipeline = pipeline_name
                    ssim_inputs = (t_auto, q_auto)
                else:
                    euclidean_dist = dist_fallback
                    pipeline = 'classical'
                    ssim_inputs = (fallback_template, fallback_query)
            else:
                # å¤§å·®å¼‚ï¼šä¿å®ˆç­–ç•¥ï¼Œä½¿ç”¨æ›´å¤§è·ç¦»ï¼ˆæ›´éš¾é€šè¿‡ï¼Œé™ä½è¯¯é€šè¿‡ï¼‰
                if dist_auto >= dist_fallback:
                    euclidean_dist = dist_auto
                    pipeline = pipeline_name
                    ssim_inputs = (t_auto, q_auto)
                else:
                    euclidean_dist = dist_fallback
                    pipeline = 'classical'
                    ssim_inputs = (fallback_template, fallback_query)
        
        # è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°(0-1)
        threshold_dist = 0.15  # SigNetè®ºæ–‡é˜ˆå€¼
        similarity = np.exp(-euclidean_dist / threshold_dist)

        # ç»“æ„ç›¸ä¼¼åº¦è¾…åŠ©
        try:
            ssim_score = compute_ssim_similarity(ssim_inputs[0], ssim_inputs[1])
        except Exception:
            ssim_score = None
        
        result = {
            'similarity': float(similarity),
            'distance': float(euclidean_dist),
            'distance_classical': float(dist_fallback),
            'distance_auto': (float(dist_auto) if dist_auto is not None else None),
            'ssim': float(ssim_score) if ssim_score is not None else None,
            'pipeline': pipeline,
            'clean_enabled': enable_clean,
            'clean_mode': clean_mode if enable_clean else None
        }
        
        # ä¿å­˜é«˜åˆ†è¾¨ç‡æ¸…æ´å›¾ç‰‡ç”¨äºå‰ç«¯å±•ç¤º
        if enable_clean and template_cleaned_display is not None and query_cleaned_display is not None:
            try:
                debug_dir = 'uploaded_samples/debug'
                os.makedirs(debug_dir, exist_ok=True)
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                
                # ä¿å­˜åŸå§‹å°ºå¯¸çš„æ¸…æ´å›¾ç‰‡
                template_path = f'{debug_dir}/template_cleaned_{timestamp}.png'
                query_path = f'{debug_dir}/query_cleaned_{timestamp}.png'
                
                cv2.imwrite(template_path, template_cleaned_display)
                cv2.imwrite(query_path, query_cleaned_display)
                
                result['debug_images'] = {
                    'template': f'debug/template_cleaned_{timestamp}.png',
                    'query': f'debug/query_cleaned_{timestamp}.png'
                }
                
                print(f"âœ… å·²ä¿å­˜æ¸…æ´å›¾ç‰‡: {template_path} ({template_cleaned_display.shape})")
                print(f"âœ… å·²ä¿å­˜æ¸…æ´å›¾ç‰‡: {query_path} ({query_cleaned_display.shape})")
                
            except Exception as e:
                print(f"âš ï¸ ä¿å­˜è°ƒè¯•å›¾åƒå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        return result
    except Exception as e:
        print(f"âš ï¸ SigNetå¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def compute_clip_similarity(template_img, query_img):
    """ä½¿ç”¨CLIPè®¡ç®—å›¾åƒç›¸ä¼¼åº¦"""
    # CLIPé¢„å¤„ç†å’Œç‰¹å¾æå–
    template_input = clip_preprocess(template_img).unsqueeze(0).to(device)
    query_input = clip_preprocess(query_img).unsqueeze(0).to(device)
    
    # æå–ç‰¹å¾
    with torch.no_grad():
        template_features = clip_model.encode_image(template_input)
        query_features = clip_model.encode_image(query_input)
        
        # L2å½’ä¸€åŒ–
        template_features = template_features / template_features.norm(dim=-1, keepdim=True)
        query_features = query_features / query_features.norm(dim=-1, keepdim=True)
    
    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    similarity = float(F.cosine_similarity(template_features, query_features))
    return similarity

@app.post("/api/verify")
async def verify_signature(
    template_image: UploadFile = File(...),
    query_image: UploadFile = File(...),
    verification_type: str = Form(default="signature"),
    algorithm: str = Form(default="signet"),
    enable_clean: bool = Form(default=True),
    clean_mode: str = Form(default="conservative")
):
    """
    éªŒè¯ç­¾åæˆ–å›¾ç« çš„ç›¸ä¼¼åº¦
    
    ç®—æ³•é€‰é¡¹:
    - signet: SigNetä¸“ä¸šæ¨¡å‹(é»˜è®¤,é€‚åˆç­¾å)
    - clip: CLIPè§†è§‰æ¨¡å‹(é€‚åˆå°ç« )
    
    å‚æ•°:
    - algorithm: éªŒè¯ç®—æ³• ('signet', 'clip')
    - enable_clean: æ˜¯å¦å¯ç”¨ç­¾åæ¸…æ´ï¼ˆå»é™¤æ‚è´¨ï¼‰
    - clean_mode: æ¸…æ´æ¨¡å¼ 'conservative'(ä¸­æ–‡ç­¾å) æˆ– 'aggressive'(è‹±æ–‡ç­¾å)
    """
    start_time = time.time()

    degraded_mode = False
    degraded_reason = None
    algorithm_remapped_from = None

    try:
        # è¯»å–å›¾ç‰‡ï¼ˆä¸€æ¬¡è¯»å–å­—èŠ‚ï¼ŒæŒ‰éœ€ç”Ÿæˆç°åº¦/å½©è‰²ç‰ˆæœ¬ï¼‰
        template_bytes = await template_image.read()
        query_bytes = await query_image.read()

        # ç­¾åï¼šç°åº¦ï¼›å°ç« ï¼šCLIP æ›´é€‚åˆç”¨ RGBï¼ˆä¿ç•™çº¢ç« é¢œè‰²ä¿¡æ¯ï¼‰
        template_img = _open_image_as_grayscale(template_bytes)
        query_img = _open_image_as_grayscale(query_bytes)
        template_img_rgb = _open_image_as_rgb(template_bytes)
        query_img_rgb = _open_image_as_rgb(query_bytes)

        # âœ… å…œåº•ï¼šå°ç« éªŒè¯å¼ºåˆ¶ä½¿ç”¨ CLIPï¼Œé¿å…è¯¯ç”¨ SigNet
        if verification_type == "seal":
            algorithm = "clip"

        # âœ… å…¼å®¹æ—§è¯·æ±‚ï¼šé¡¹ç›®å·²ç§»é™¤ GNNï¼Œä½†ä¸ºäº†ä¸ç ´åæ—§è°ƒç”¨ï¼Œè‡ªåŠ¨æ˜ å°„åˆ° SigNet
        if algorithm == "gnn":
            algorithm_remapped_from = "gnn"
            algorithm = "signet"

        # ğŸ”¥ ä¿å­˜ç”¨æˆ·ä¸Šä¼ çš„çœŸå®è£å‰ªå›¾ç‰‡
        save_dir = "uploaded_samples"
        os.makedirs(save_dir, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        template_path = os.path.join(save_dir, f"{verification_type}_template_{timestamp}.png")
        query_path = os.path.join(save_dir, f"{verification_type}_query_{timestamp}.png")

        # ä¿å­˜ç”¨äºè°ƒè¯•çš„è¾“å…¥å›¾ï¼ˆç­¾åä¿å­˜ç°åº¦ï¼›å°ç« ä¿å­˜RGBï¼‰
        if verification_type == "seal":
            template_img_rgb.save(template_path)
            query_img_rgb.save(query_path)
        else:
            template_img.save(template_path)
            query_img.save(query_path)
        print(f"ğŸ’¾ å·²ä¿å­˜æ ·æœ¬: {template_path}, {query_path}")
        
        # âœ… ç¬”ç”»ç‰¹å¾å¿«é€Ÿç­›é€‰ (ä»…ç­¾å). å°ç« ä¸åšè¯¥ç­›é€‰ï¼Œé¿å…è¯¯æ€
        if verification_type == "signature":
            from stroke_analyzer import quick_signature_check
            template_np = np.array(template_img)
            query_np = np.array(query_img)

            # æ›´ä¿å®ˆçš„å¿«é€Ÿæ‹’ç»é˜ˆå€¼ï¼šä¼˜å…ˆé™ä½è¯¯æ€ï¼ˆå‡†ç¡®ç‡/å¬å›æ›´é‡è¦ï¼‰
            stroke_thresholds = {
                'stroke_count_diff_max': 0.70,
                'aspect_ratio_diff_max': 0.75,
                'density_diff_max': 0.75,
                'bbox_area_diff_max': 0.85,
                'combined_score_max': 1.85,
            }

            stroke_check = quick_signature_check(template_np, query_np, thresholds=stroke_thresholds)
            print(f"ğŸ” ç¬”ç”»ç‰¹å¾æ£€æŸ¥: {stroke_check}")
            
            if stroke_check['should_reject']:
                # å¿«é€Ÿæ‹’ç»,ä¸éœ€è¦æ·±åº¦å­¦ä¹ æ¨¡å‹
                processing_time = time.time() - start_time
                result = {
                    "success": True,  # æ·»åŠ successå­—æ®µ
                    "match": False,
                    "final_score": 0.0,  # æ·»åŠ final_scoreå­—æ®µ
                    "confidence": "low",  # ç½®ä¿¡åº¦æ”¹ä¸ºå­—ç¬¦ä¸²
                    "algorithm": "ç¬”ç”»ç­›é€‰å™¨",
                    "algorithm_used": "stroke_filter",
                    "type": verification_type,  # æ·»åŠ typeå­—æ®µ
                    "verification_type": verification_type,
                    "template_path": template_path,
                    "query_path": query_path,
                    "fast_reject": True,
                    "reject_reason": stroke_check['reason'],
                    "stroke_features": {
                        "template": stroke_check['template_features'],
                        "query": stroke_check['query_features'],
                        "differences": stroke_check['differences']
                    },
                    "processing_time_ms": round(processing_time * 1000, 2)
                }
                return result
            
            print("âœ… ç¬”ç”»ç‰¹å¾æ£€æŸ¥é€šè¿‡,ç»§ç»­æ·±åº¦å­¦ä¹ éªŒè¯...")
        
        # æ ¹æ®ç®—æ³•é€‰æ‹©è®¡ç®—ç›¸ä¼¼åº¦
        algorithm_used = ""
        euclidean_distance = None
        result = None
        
        if algorithm == "signet":
            # ä½¿ç”¨SigNetéªŒè¯ï¼ˆæ”¯æŒæ¸…æ´åŠŸèƒ½ï¼‰
            print("ğŸ”¬ ä½¿ç”¨SigNetç®—æ³•...")
            result = compute_signet_similarity(
                template_img, 
                query_img, 
                enable_clean=enable_clean,
                clean_mode=clean_mode
            )
            if result is not None:
                similarity = result['similarity']
                euclidean_distance = result['distance']
                signature_ssim = result.get('ssim')
                pipeline = result.get('pipeline', 'SigNet')
                clean_info = f"+clean({clean_mode})" if result.get('clean_enabled') else ""
                algorithm_used = f"SigNet[{pipeline}{clean_info}]"
                threshold = 0.92  # SigNeté˜ˆå€¼
                # SSIM ä»…ä½œä¸ºè¯Šæ–­æŒ‡æ ‡è¿”å›ï¼Œä¸ç›´æ¥æŠ¬å‡æœ€ç»ˆåˆ†æ•°ï¼Œé¿å…è¯¯é€šè¿‡
            else:
                # SigNetå¤±è´¥ï¼šåªåšè¯Šæ–­æ€§ CLIP fallbackï¼Œä½†ä¸å…è®¸è‡ªåŠ¨é€šè¿‡
                degraded_mode = True
                degraded_reason = "SigNet unavailable or failed; falling back to CLIP for diagnostic only"
                similarity = compute_clip_similarity(template_img, query_img)
                algorithm_used = "CLIP(fallback)"
                threshold = 0.99
        
        elif algorithm == "clip":
            # ä½¿ç”¨CLIPéªŒè¯
            print("ğŸ¨ ä½¿ç”¨CLIPç®—æ³•...")
            # å°ç« ä¼˜å…ˆä½¿ç”¨RGBè¾“å…¥ï¼ˆä¿ç•™çº¢ç« ä¿¡æ¯ï¼‰
            if verification_type == "seal":
                similarity = compute_clip_similarity(template_img_rgb, query_img_rgb)
            else:
                similarity = compute_clip_similarity(template_img, query_img)
            algorithm_used = "CLIP"
            threshold = 0.88 if verification_type == "seal" else 0.85
        
        # å¦‚æœè¿˜æ²¡æœ‰è®¾ç½®algorithm_used(è¯´æ˜ä¸Šé¢çš„é€»è¾‘æ²¡æœ‰æ‰§è¡Œ),ä½¿ç”¨é»˜è®¤
        if not algorithm_used:
            if verification_type == "signature":
                result = compute_signet_similarity(
                    template_img, 
                    query_img, 
                    enable_clean=enable_clean,
                    clean_mode=clean_mode
                )
                if result is not None:
                    similarity = result['similarity']
                    euclidean_distance = result['distance']
                    algorithm_used = "SigNet"
                    threshold = 0.92
                else:
                    degraded_mode = True
                    degraded_reason = "SigNet unavailable or failed; falling back to CLIP for diagnostic only"
                    similarity = compute_clip_similarity(template_img, query_img)
                    algorithm_used = "CLIP(fallback)"
                    threshold = 0.99
            else:
                # å°ç« ç”¨CLIP
                similarity = compute_clip_similarity(template_img_rgb, query_img_rgb)
                algorithm_used = "CLIP"
                threshold = 0.88
        
        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        print(f"\n{'='*60}")
        print(f"ğŸ” éªŒè¯ç±»å‹: {verification_type}")
        print(f"ğŸ¤– ä½¿ç”¨ç®—æ³•: {algorithm_used}")
        print(f"ğŸ¯ ç›¸ä¼¼åº¦: {similarity:.4f}")
        if euclidean_distance is not None:
            print(f"ğŸ“ æ¬§æ°è·ç¦»: {euclidean_distance:.4f}")
        if verification_type == "signature" and result is not None and result.get('ssim') is not None:
            print(f"ğŸ§® SSIM: {result['ssim']:.4f}")
        print(f"ğŸ“Š é˜ˆå€¼: {threshold:.4f}")
        print(f"{'='*60}\n")
        
        # ä½¿ç”¨è®¡ç®—å‡ºçš„ç›¸ä¼¼åº¦
        final_score = similarity
        
        # ç½®ä¿¡åº¦è¯„ä¼°ï¼ˆåªåŸºäºCLIPï¼‰
        if degraded_mode:
            confidence = 'low'
        else:
            if final_score > threshold + 0.05:
                confidence = 'high'
            elif final_score < threshold - 0.10:
                confidence = 'low'
            else:
                confidence = 'medium'
        
        # ç”Ÿæˆå»ºè®®
        type_name = "ç­¾å" if verification_type == 'signature' else "å›¾ç« "
        if confidence == 'high':
            if final_score > threshold:
                recommendation = f"é«˜ç½®ä¿¡åº¦é€šè¿‡ - {type_name}é«˜åº¦ç›¸ä¼¼ï¼Œå¯è‡ªåŠ¨æ¥å—"
            else:
                recommendation = f"é«˜ç½®ä¿¡åº¦æ‹’ç» - {type_name}å·®å¼‚æ˜æ˜¾ï¼Œå¯è‡ªåŠ¨æ‹’ç»"
        elif confidence == 'medium':
            recommendation = f"ä¸­ç­‰ç½®ä¿¡åº¦ - {type_name}ç›¸ä¼¼åº¦{final_score:.1%}ï¼Œå»ºè®®äººå·¥å¤å®¡"
        else:
            recommendation = f"ä½ç½®ä¿¡åº¦ - {type_name}ç‰¹å¾ä¸æ˜ç¡®ï¼Œå¼ºçƒˆå»ºè®®ä¸“å®¶å¤å®¡"
        
        processing_time = time.time() - start_time
        
        response_data = {
            'success': True,
            'type': verification_type,
            'algorithm': algorithm_used,
            'similarity': round(similarity, 4),
            'euclidean_distance': round(euclidean_distance, 4) if euclidean_distance is not None else None,
            'ssim': round(result['ssim'], 4) if verification_type == "signature" and result is not None and result.get('ssim') is not None else None,
            'signet_pipeline': result.get('pipeline') if verification_type == "signature" and result is not None else None,
            'final_score': round(final_score, 4),
            'confidence': confidence,
            # é™çº§æ¨¡å¼ä¸‹ç¦æ­¢è‡ªåŠ¨é€šè¿‡ï¼ˆé¿å… CLIP å¯¹ç­¾åè¯¯åˆ¤ï¼‰
            'is_authentic': (False if degraded_mode else (final_score > threshold and confidence != 'low')),
            'threshold': threshold,
            'recommendation': recommendation,
            'processing_time_ms': round(processing_time * 1000, 2),
            'clean_enabled': enable_clean if verification_type == "signature" else None,
            'clean_mode': clean_mode if verification_type == "signature" and enable_clean else None,
            # å…¼å®¹æ—§å­—æ®µï¼ˆå†å²ä¸Šç”¨äº GNNï¼‰
            'gnn_keypoints_template': None,
            'gnn_keypoints_query': None,
            'gnn_distance': None
        }

        if algorithm_remapped_from is not None:
            response_data['notice'] = f"algorithm '{algorithm_remapped_from}' å·²ç§»é™¤ï¼Œå·²è‡ªåŠ¨ä½¿ç”¨ 'signet'"

        if degraded_mode:
            response_data['degraded_mode'] = True
            response_data['warning'] = degraded_reason
        
        # æ·»åŠ è°ƒè¯•å›¾åƒè·¯å¾„ï¼ˆå¦‚æœæœ‰ï¼‰
        if verification_type == "signature" and result is not None and 'debug_images' in result:
            response_data['debug_images'] = result['debug_images']
        
        return response_data
        
    except Exception as e:
        import traceback
        return JSONResponse(
            status_code=500,
            content={
                'success': False,
                'error': str(e),
                'traceback': traceback.format_exc()
            }
        )

# æŒ‚è½½å‰ç«¯é™æ€æ–‡ä»¶ (ç”¨äºå•å®¹å™¨éƒ¨ç½²)
# æ³¨æ„: é™æ€æ–‡ä»¶è·¯ç”±å¿…é¡»æ”¾åœ¨æœ€å,é¿å…è¦†ç›–APIè·¯ç”±
frontend_path = os.path.join(os.path.dirname(__file__), "..", "frontend")
if os.path.exists(frontend_path):
    app.mount("/", StaticFiles(directory=frontend_path, html=True), name="static")
    print(f"âœ… å‰ç«¯é™æ€æ–‡ä»¶å·²æŒ‚è½½: {frontend_path}")
else:
    print(f"âš ï¸ å‰ç«¯ç›®å½•ä¸å­˜åœ¨: {frontend_path}")

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ å¯åŠ¨æœåŠ¡å™¨: http://localhost:8000")
    print("ğŸ“– APIæ–‡æ¡£: http://localhost:8000/docs")
    print("ğŸ¨ å‰ç«¯ç•Œé¢: http://localhost:8000")
    uvicorn.run(app, host="0.0.0.0", port=8000)
