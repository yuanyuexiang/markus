"""
ç­¾åå›¾ç« éªŒè¯ç³»ç»Ÿ - åç«¯API
ç­¾å: SigNetä¸“ä¸šæ¨¡å‹
å°ç« : CLIPå›¾åƒç›¸ä¼¼åº¦
"""
from fastapi import FastAPI, File, UploadFile, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles
import clip
import torch
from PIL import Image
import io
import cv2
import numpy as np
from typing import Literal
import torch.nn.functional as F
import time
import os
from datetime import datetime

app = FastAPI(title="ç­¾åå›¾ç« éªŒè¯ç³»ç»Ÿ")

# å…è®¸è·¨åŸŸ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# GNNéªŒè¯å™¨å»¶è¿ŸåŠ è½½
gnn_verifier = None

def load_gnn_verifier():
    """å»¶è¿ŸåŠ è½½GNNéªŒè¯å™¨"""
    global gnn_verifier
    if gnn_verifier is not None:
        return gnn_verifier
    
    try:
        import sys
        import os
        # æ·»åŠ backendç›®å½•åˆ°Pythonè·¯å¾„
        backend_dir = os.path.dirname(os.path.abspath(__file__))
        if backend_dir not in sys.path:
            sys.path.insert(0, backend_dir)
        
        from gnn_verifier import get_gnn_verifier
        gnn_verifier = get_gnn_verifier()
        print("âœ… GNNéªŒè¯å™¨åŠ è½½å®Œæˆ")
        return gnn_verifier
    except Exception as e:
        import traceback
        print(f"âš ï¸ GNNéªŒè¯å™¨åŠ è½½å¤±è´¥: {e}")
        print(traceback.format_exc())
        return None

# æŒ‚è½½é™æ€æ–‡ä»¶æœåŠ¡ï¼Œç”¨äºè®¿é—®ä¸Šä¼ çš„æ ·æœ¬å’Œè°ƒè¯•å›¾ç‰‡
app.mount("/uploaded_samples", StaticFiles(directory="uploaded_samples"), name="uploaded_samples")

# å…¨å±€åŠ è½½CLIPæ¨¡å‹(å°ç« ä½¿ç”¨)
print("ğŸ”„ æ­£åœ¨åŠ è½½CLIPæ¨¡å‹...")
device = "cpu"
clip_model, clip_preprocess = clip.load("ViT-B/32", device=device)
print("âœ… CLIPæ¨¡å‹åŠ è½½å®Œæˆ")

# SigNetå»¶è¿ŸåŠ è½½(é¿å…TensorFlowå¯åŠ¨é˜»å¡)
signet_model = None
_signet_imports = {}

def load_signet_model():
    """å»¶è¿ŸåŠ è½½SigNetæ¨¡å‹(é¦–æ¬¡è°ƒç”¨æ—¶åŠ è½½)"""
    global signet_model, _signet_imports
    if signet_model is not None:
        return signet_model
    
    try:
        from signet_model import SigNetModel
        from preprocess.normalize import preprocess_signature
        _signet_imports['SigNetModel'] = SigNetModel
        _signet_imports['preprocess_signature'] = preprocess_signature
        
        signet_model = SigNetModel('models/signet.pkl')
        print("âœ… SigNetç­¾åéªŒè¯æ¨¡å‹åŠ è½½å®Œæˆ")
        return signet_model
    except Exception as e:
        print(f"âš ï¸ SigNetæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

def preprocess_for_feature_matching(img_cv: np.ndarray) -> np.ndarray:
    """
    å›¾åƒé¢„å¤„ç†ç”¨äºç‰¹å¾ç‚¹åŒ¹é…
    1. è‡ªé€‚åº”äºŒå€¼åŒ–ï¼šå»é™¤èƒŒæ™¯å™ªå£°
    2. å½¢æ€å­¦å¤„ç†ï¼šè¿æ¥æ–­ç‚¹ï¼Œå»é™¤å°å™ªç‚¹
    """
    # è‡ªé€‚åº”é˜ˆå€¼äºŒå€¼åŒ–ï¼ˆå¯¹ä¸å‡åŒ€å…‰ç…§æ›´é²æ£’ï¼‰
    binary = cv2.adaptiveThreshold(
        img_cv, 255, 
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY, 
        blockSize=11,  # é‚»åŸŸå¤§å°
        C=2  # å¸¸æ•°åç§»
    )
    
    # å½¢æ€å­¦é—­è¿ç®—ï¼šè¿æ¥æ–­å¼€çš„ç¬”ç”»
    kernel = np.ones((3, 3), np.uint8)
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
    
    # å»é™¤å°å™ªç‚¹
    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
    
    return binary

def normalize_and_resize(img: np.ndarray, target_size: int = None) -> np.ndarray:
    """
    æ™ºèƒ½æ ‡å‡†åŒ–ï¼šä¿æŒé•¿å®½æ¯”ï¼Œè‡ªé€‚åº”é€‰æ‹©ç›®æ ‡å°ºå¯¸
    - å°å›¾ç‰‡ï¼ˆ<300pxï¼‰ï¼šæ”¾å¤§åˆ°è‡³å°‘300px
    - å¤§å›¾ç‰‡ï¼ˆ>800pxï¼‰ï¼šç¼©å°åˆ°800pxä»¥å†…
    - ä¸­ç­‰å›¾ç‰‡ï¼šä¿æŒåŸæ ·
    """
    h, w = img.shape[:2]
    max_dim = max(h, w)
    
    # æ ¹æ®åŸå›¾å°ºå¯¸è‡ªé€‚åº”ç›®æ ‡å°ºå¯¸
    if target_size is None:
        if max_dim < 300:
            target_size = 300  # å°å›¾æ”¾å¤§
        elif max_dim > 800:
            target_size = 800  # å¤§å›¾ç¼©å°
        else:
            target_size = max_dim  # ä¸­ç­‰å›¾ä¿æŒ
    
    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
    scale = target_size / max_dim
    new_w = int(w * scale)
    new_h = int(h * scale)
    
    # ç­‰æ¯”ä¾‹ç¼©æ”¾
    if scale != 1.0:
        resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA if scale < 1 else cv2.INTER_CUBIC)
    else:
        resized = img.copy()
    
    # åˆ›å»ºæ­£æ–¹å½¢ç”»å¸ƒï¼ˆç™½è‰²èƒŒæ™¯ï¼‰
    canvas = np.ones((target_size, target_size), dtype=np.uint8) * 255
    
    # å°†ç¼©æ”¾åçš„å›¾ç‰‡å±…ä¸­æ”¾ç½®
    y_offset = (target_size - new_h) // 2
    x_offset = (target_size - new_w) // 2
    canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized
    
    return canvas, scale

def compute_feature_similarity(img1: Image.Image, img2: Image.Image) -> float:
    """
    ç‰¹å¾ç‚¹åŒ¹é…å·²ç¦ç”¨ - åªä½¿ç”¨CLIP
    """
    return 0.0  # ä¸å†ä½¿ç”¨ç‰¹å¾ç‚¹åŒ¹é…

def compute_ssim_similarity(img1: np.ndarray, img2: np.ndarray) -> float:
    """è®¡ç®—ç»“æ„ç›¸ä¼¼åº¦ï¼ˆSSIMï¼‰ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ"""
    try:
        from skimage.metrics import structural_similarity as ssim
        score = ssim(img1, img2)
        return max(0.0, min(1.0, score))
    except:
        # å¦‚æœssimä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€å•çš„MSE
        mse = np.mean((img1.astype(float) - img2.astype(float)) ** 2)
        similarity = 1.0 / (1.0 + mse / 1000.0)
        return float(similarity)

def compute_signet_similarity(template_img, query_img, enable_clean=True, clean_mode='conservative'):
    """ä½¿ç”¨SigNetè®¡ç®—ç­¾åç›¸ä¼¼åº¦ï¼Œæ”¯æŒç­¾åæ¸…æ´åŠŸèƒ½
    
    Args:
        template_img: æ¨¡æ¿å›¾åƒ
        query_img: æŸ¥è¯¢å›¾åƒ
        enable_clean: æ˜¯å¦å¯ç”¨ç­¾åæ¸…æ´
        clean_mode: æ¸…æ´æ¨¡å¼ 'conservative'(ä¸­æ–‡) æˆ– 'aggressive'(è‹±æ–‡)
    
    Returns:
        åŒ…å«ç›¸ä¼¼åº¦ã€è·ç¦»ã€SSIMã€å¤„ç†æµç¨‹ä¿¡æ¯çš„å­—å…¸
    """
    model = load_signet_model()
    if model is None:
        return None
    
    try:
        preprocess_signature = _signet_imports['preprocess_signature']
        # å»¶è¿Ÿå¯¼å…¥å¢å¼ºé¢„å¤„ç†
        try:
            from preprocess.auto_crop import robust_preprocess, robust_preprocess_with_clean, clean_signature_with_morph
        except Exception as _e:
            robust_preprocess = None
            robust_preprocess_with_clean = None
            clean_signature_with_morph = None
        
        # è½¬æ¢PIL Imageåˆ°numpy array (ç°åº¦å›¾)
        template_np = np.array(template_img.convert('L'))
        query_np = np.array(query_img.convert('L'))
        
        # ä¿å­˜é«˜åˆ†è¾¨ç‡çš„æ¸…æ´å›¾ç‰‡ï¼ˆç”¨äºå‰ç«¯å±•ç¤ºï¼‰
        template_cleaned_display = None
        query_cleaned_display = None
        
        if enable_clean and clean_signature_with_morph is not None:
            # å¯¹åŸå§‹å›¾ç‰‡è¿›è¡Œæ¸…æ´ï¼Œä¿æŒåŸå§‹å°ºå¯¸
            template_cleaned_display = clean_signature_with_morph(template_np, mode=clean_mode)
            query_cleaned_display = clean_signature_with_morph(query_np, mode=clean_mode)
            # åè½¬ï¼ˆæ¸…æ´åæ˜¯å‰æ™¯255ï¼Œéœ€è¦è½¬æˆèƒŒæ™¯255ï¼‰
            template_cleaned_display = cv2.bitwise_not(template_cleaned_display)
            query_cleaned_display = cv2.bitwise_not(query_cleaned_display)
        
        # ä¼ ç»Ÿé¢„å¤„ç†è·¯å¾„ï¼ˆå›é€€ï¼‰
        fallback_template = preprocess_signature(template_np, canvas_size=(952, 1360))
        fallback_query = preprocess_signature(query_np, canvas_size=(952, 1360))

        # é€‰æ‹©å¢å¼ºé¢„å¤„ç†è·¯å¾„
        if enable_clean and robust_preprocess_with_clean is not None:
            # ä½¿ç”¨å¸¦æ¸…æ´çš„é¢„å¤„ç†
            t_auto = robust_preprocess_with_clean(template_np, clean_mode=clean_mode)
            q_auto = robust_preprocess_with_clean(query_np, clean_mode=clean_mode)
            pipeline_name = f'robust+clean({clean_mode})'
        elif robust_preprocess is not None:
            # ä½¿ç”¨æ— æ¸…æ´çš„é²æ£’é¢„å¤„ç†
            t_auto = robust_preprocess(template_np)
            q_auto = robust_preprocess(query_np)
            pipeline_name = 'robust'
        else:
            t_auto = q_auto = None
            pipeline_name = 'classical'

        auto_valid = (
            t_auto is not None and q_auto is not None and
            t_auto.shape == (150, 220) and q_auto.shape == (150, 220)
        )

        # è®¡ç®—ä¸¤æ¡è·¯å¾„çš„è·ç¦»
        dist_fallback = model.compute_similarity(fallback_template, fallback_query)
        dist_auto = None
        if auto_valid:
            dist_auto = model.compute_similarity(t_auto, q_auto)

        # é€‰æ‹©æ›´ä¼˜è·¯å¾„
        if dist_auto is not None and dist_auto <= dist_fallback:
            euclidean_dist = dist_auto
            pipeline = pipeline_name
            ssim_inputs = (t_auto, q_auto)
        else:
            euclidean_dist = dist_fallback
            pipeline = 'classical'
            # SSIM ä¼˜å…ˆä½¿ç”¨è‡ªåŠ¨è£å‰ªç»“æœ
            if auto_valid:
                ssim_inputs = (t_auto, q_auto)
            else:
                ssim_inputs = (fallback_template, fallback_query)
        
        # è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°(0-1)
        threshold_dist = 0.15  # SigNetè®ºæ–‡é˜ˆå€¼
        similarity = np.exp(-euclidean_dist / threshold_dist)

        # ç»“æ„ç›¸ä¼¼åº¦è¾…åŠ©
        try:
            ssim_score = compute_ssim_similarity(ssim_inputs[0], ssim_inputs[1])
        except Exception:
            ssim_score = None
        
        result = {
            'similarity': float(similarity),
            'distance': float(euclidean_dist),
            'ssim': float(ssim_score) if ssim_score is not None else None,
            'pipeline': pipeline,
            'clean_enabled': enable_clean,
            'clean_mode': clean_mode if enable_clean else None
        }
        
        # ä¿å­˜é«˜åˆ†è¾¨ç‡æ¸…æ´å›¾ç‰‡ç”¨äºå‰ç«¯å±•ç¤º
        if enable_clean and template_cleaned_display is not None and query_cleaned_display is not None:
            try:
                debug_dir = 'uploaded_samples/debug'
                os.makedirs(debug_dir, exist_ok=True)
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                
                # ä¿å­˜åŸå§‹å°ºå¯¸çš„æ¸…æ´å›¾ç‰‡
                template_path = f'{debug_dir}/template_cleaned_{timestamp}.png'
                query_path = f'{debug_dir}/query_cleaned_{timestamp}.png'
                
                cv2.imwrite(template_path, template_cleaned_display)
                cv2.imwrite(query_path, query_cleaned_display)
                
                result['debug_images'] = {
                    'template': f'debug/template_cleaned_{timestamp}.png',
                    'query': f'debug/query_cleaned_{timestamp}.png'
                }
                
                print(f"âœ… å·²ä¿å­˜æ¸…æ´å›¾ç‰‡: {template_path} ({template_cleaned_display.shape})")
                print(f"âœ… å·²ä¿å­˜æ¸…æ´å›¾ç‰‡: {query_path} ({query_cleaned_display.shape})")
                
            except Exception as e:
                print(f"âš ï¸ ä¿å­˜è°ƒè¯•å›¾åƒå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        return result
    except Exception as e:
        print(f"âš ï¸ SigNetå¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def compute_clip_similarity(template_img, query_img):
    """ä½¿ç”¨CLIPè®¡ç®—å›¾åƒç›¸ä¼¼åº¦"""
    # CLIPé¢„å¤„ç†å’Œç‰¹å¾æå–
    template_input = clip_preprocess(template_img).unsqueeze(0).to(device)
    query_input = clip_preprocess(query_img).unsqueeze(0).to(device)
    
    # æå–ç‰¹å¾
    with torch.no_grad():
        template_features = clip_model.encode_image(template_input)
        query_features = clip_model.encode_image(query_input)
        
        # L2å½’ä¸€åŒ–
        template_features = template_features / template_features.norm(dim=-1, keepdim=True)
        query_features = query_features / query_features.norm(dim=-1, keepdim=True)
    
    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    similarity = float(F.cosine_similarity(template_features, query_features))
    return similarity

@app.post("/api/verify")
async def verify_signature(
    template_image: UploadFile = File(...),
    query_image: UploadFile = File(...),
    verification_type: str = Form(default="signature"),
    algorithm: str = Form(default="signet"),  # æ–°å¢: signet, gnn, clip
    enable_clean: bool = Form(default=True),
    clean_mode: str = Form(default="conservative")
):
    """
    éªŒè¯ç­¾åæˆ–å›¾ç« çš„ç›¸ä¼¼åº¦
    
    ç®—æ³•é€‰é¡¹:
    - signet: SigNetä¸“ä¸šæ¨¡å‹(é»˜è®¤,é€‚åˆç­¾å)
    - gnn: å›¾ç¥ç»ç½‘ç»œ(åŸºäºå…³é”®ç‚¹ç»“æ„)
    - clip: CLIPè§†è§‰æ¨¡å‹(é€‚åˆå°ç« )
    
    å‚æ•°:
    - algorithm: éªŒè¯ç®—æ³• ('signet', 'gnn', 'clip')
    - enable_clean: æ˜¯å¦å¯ç”¨ç­¾åæ¸…æ´ï¼ˆå»é™¤æ‚è´¨ï¼‰
    - clean_mode: æ¸…æ´æ¨¡å¼ 'conservative'(ä¸­æ–‡ç­¾å) æˆ– 'aggressive'(è‹±æ–‡ç­¾å)
    """
    start_time = time.time()

    try:
        # è¯»å–å›¾ç‰‡å¹¶ç›´æ¥è½¬ä¸ºç°åº¦L
        template_img = Image.open(io.BytesIO(await template_image.read())).convert('L')
        query_img = Image.open(io.BytesIO(await query_image.read())).convert('L')

        # ğŸ”¥ ä¿å­˜ç”¨æˆ·ä¸Šä¼ çš„çœŸå®è£å‰ªå›¾ç‰‡
        save_dir = "uploaded_samples"
        os.makedirs(save_dir, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        template_path = os.path.join(save_dir, f"{verification_type}_template_{timestamp}.png")
        query_path = os.path.join(save_dir, f"{verification_type}_query_{timestamp}.png")

        template_img.save(template_path)
        query_img.save(query_path)
        print(f"ğŸ’¾ å·²ä¿å­˜æ ·æœ¬: {template_path}, {query_path}")
        
        # æ ¹æ®ç®—æ³•é€‰æ‹©è®¡ç®—ç›¸ä¼¼åº¦
        algorithm_used = ""
        euclidean_distance = None
        result = None
        gnn_info = {}
        
        # å¼ºåˆ¶ç®—æ³•é€‰æ‹©é€»è¾‘
        if algorithm == "gnn":
            # ä½¿ç”¨GNNéªŒè¯
            print("ğŸ§  ä½¿ç”¨GNNç®—æ³•...")
            gnn = load_gnn_verifier()
            if gnn is not None and gnn.model is not None:
                # è½¬ä¸ºnumpyæ•°ç»„
                template_np = np.array(template_img)
                query_np = np.array(query_img)
                
                # GNNè‡ªåŠ¨ä½¿ç”¨ç­¾åæ¸…æ´åŠŸèƒ½ (ä¿å®ˆæ¨¡å¼é€‚åˆä¸­æ–‡ç­¾å)
                try:
                    from preprocess.auto_crop import clean_signature_with_morph
                    # æ¸…æ´å›¾ç‰‡å»é™¤å™ªå£°
                    template_cleaned = clean_signature_with_morph(template_np, mode='conservative')
                    query_cleaned = clean_signature_with_morph(query_np, mode='conservative')
                    # åè½¬ (æ¸…æ´åæ˜¯å‰æ™¯255,éœ€è¦è½¬æˆèƒŒæ™¯255)
                    template_cleaned = cv2.bitwise_not(template_cleaned)
                    query_cleaned = cv2.bitwise_not(query_cleaned)
                    
                    # ä¿å­˜æ¸…æ´åçš„å›¾ç‰‡ç”¨äºè°ƒè¯•
                    debug_dir = os.path.join(save_dir, "debug")
                    os.makedirs(debug_dir, exist_ok=True)
                    template_clean_path = os.path.join(debug_dir, f"template_cleaned_{timestamp}.png")
                    query_clean_path = os.path.join(debug_dir, f"query_cleaned_{timestamp}.png")
                    cv2.imwrite(template_clean_path, template_cleaned)
                    cv2.imwrite(query_clean_path, query_cleaned)
                    print(f"âœ… GNNå·²ä¿å­˜æ¸…æ´å›¾ç‰‡: {template_clean_path}, {query_clean_path}")
                    
                    # ä½¿ç”¨æ¸…æ´åçš„å›¾ç‰‡è¿›è¡ŒGNNéªŒè¯
                    gnn_result = gnn.verify(template_cleaned, query_cleaned)
                except Exception as clean_error:
                    print(f"âš ï¸ ç­¾åæ¸…æ´å¤±è´¥,ä½¿ç”¨åŸå§‹å›¾ç‰‡: {clean_error}")
                    gnn_result = gnn.verify(template_np, query_np)
                
                if 'error' not in gnn_result:
                    # GNNæˆåŠŸ
                    similarity = gnn_result['confidence']
                    euclidean_distance = gnn_result['distance']
                    gnn_info = {
                        'keypoints_template': gnn_result['keypoints_template'],
                        'keypoints_query': gnn_result['keypoints_query'],
                        'gnn_distance': gnn_result['distance'],
                        'gnn_threshold': gnn_result['threshold']
                    }
                    algorithm_used = "GNN"
                    threshold = 0.5  # GNNä½¿ç”¨confidenceé˜ˆå€¼
                else:
                    # GNNå¤±è´¥,å›é€€åˆ°SigNet
                    print(f"âš ï¸ GNNå¤±è´¥: {gnn_result['error']}, å›é€€åˆ°SigNet")
                    algorithm = "signet"
            else:
                # GNNæœªåŠ è½½,å›é€€åˆ°SigNet
                print("âš ï¸ GNNæ¨¡å‹æœªåŠ è½½, å›é€€åˆ°SigNet")
                algorithm = "signet"
        
        if algorithm == "signet":
            # ä½¿ç”¨SigNetéªŒè¯ï¼ˆæ”¯æŒæ¸…æ´åŠŸèƒ½ï¼‰
            print("ğŸ”¬ ä½¿ç”¨SigNetç®—æ³•...")
            result = compute_signet_similarity(
                template_img, 
                query_img, 
                enable_clean=enable_clean,
                clean_mode=clean_mode
            )
            if result is not None:
                similarity = result['similarity']
                euclidean_distance = result['distance']
                signature_ssim = result.get('ssim')
                pipeline = result.get('pipeline', 'SigNet')
                clean_info = f"+clean({clean_mode})" if result.get('clean_enabled') else ""
                algorithm_used = f"SigNet[{pipeline}{clean_info}]"
                threshold = 0.92  # SigNeté˜ˆå€¼
                if signature_ssim is not None:
                    # SSIMä¸ºäººå·¥è£å‰ª/è½»å¾®å˜å½¢æä¾›å…œåº•
                    similarity = max(similarity, min(0.98, signature_ssim * 0.95))
            else:
                # SigNetå¤±è´¥,å›é€€åˆ°CLIP
                similarity = compute_clip_similarity(template_img, query_img)
                algorithm_used = "CLIP(fallback)"
                threshold = 0.85
        
        elif algorithm == "clip":
            # ä½¿ç”¨CLIPéªŒè¯
            print("ğŸ¨ ä½¿ç”¨CLIPç®—æ³•...")
            similarity = compute_clip_similarity(template_img, query_img)
            algorithm_used = "CLIP"
            threshold = 0.88 if verification_type == "seal" else 0.85
        
        # å¦‚æœè¿˜æ²¡æœ‰è®¾ç½®algorithm_used(è¯´æ˜ä¸Šé¢çš„é€»è¾‘æ²¡æœ‰æ‰§è¡Œ),ä½¿ç”¨é»˜è®¤
        if not algorithm_used:
            if verification_type == "signature":
                result = compute_signet_similarity(
                    template_img, 
                    query_img, 
                    enable_clean=enable_clean,
                    clean_mode=clean_mode
                )
                if result is not None:
                    similarity = result['similarity']
                    euclidean_distance = result['distance']
                    algorithm_used = "SigNet"
                    threshold = 0.92
                else:
                    similarity = compute_clip_similarity(template_img, query_img)
                    algorithm_used = "CLIP(fallback)"
                    threshold = 0.85
            else:
                # å°ç« ç”¨CLIP
                similarity = compute_clip_similarity(template_img, query_img)
                algorithm_used = "CLIP"
                threshold = 0.88
        
        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        print(f"\n{'='*60}")
        print(f"ğŸ” éªŒè¯ç±»å‹: {verification_type}")
        print(f"ğŸ¤– ä½¿ç”¨ç®—æ³•: {algorithm_used}")
        print(f"ğŸ¯ ç›¸ä¼¼åº¦: {similarity:.4f}")
        if euclidean_distance is not None:
            print(f"ğŸ“ æ¬§æ°è·ç¦»: {euclidean_distance:.4f}")
        if verification_type == "signature" and result is not None and result.get('ssim') is not None:
            print(f"ğŸ§® SSIM: {result['ssim']:.4f}")
        if gnn_info:
            print(f"ğŸ§  GNNå…³é”®ç‚¹: template={gnn_info['keypoints_template']}, query={gnn_info['keypoints_query']}")
        print(f"ğŸ“Š é˜ˆå€¼: {threshold:.4f}")
        print(f"{'='*60}\n")
        
        # ä½¿ç”¨è®¡ç®—å‡ºçš„ç›¸ä¼¼åº¦
        final_score = similarity
        
        # ç½®ä¿¡åº¦è¯„ä¼°ï¼ˆåªåŸºäºCLIPï¼‰
        if final_score > threshold + 0.05:
            confidence = 'high'
        elif final_score < threshold - 0.10:
            confidence = 'low'
        else:
            confidence = 'medium'
        
        # ç”Ÿæˆå»ºè®®
        type_name = "ç­¾å" if verification_type == 'signature' else "å›¾ç« "
        if confidence == 'high':
            if final_score > threshold:
                recommendation = f"é«˜ç½®ä¿¡åº¦é€šè¿‡ - {type_name}é«˜åº¦ç›¸ä¼¼ï¼Œå¯è‡ªåŠ¨æ¥å—"
            else:
                recommendation = f"é«˜ç½®ä¿¡åº¦æ‹’ç» - {type_name}å·®å¼‚æ˜æ˜¾ï¼Œå¯è‡ªåŠ¨æ‹’ç»"
        elif confidence == 'medium':
            recommendation = f"ä¸­ç­‰ç½®ä¿¡åº¦ - {type_name}ç›¸ä¼¼åº¦{final_score:.1%}ï¼Œå»ºè®®äººå·¥å¤å®¡"
        else:
            recommendation = f"ä½ç½®ä¿¡åº¦ - {type_name}ç‰¹å¾ä¸æ˜ç¡®ï¼Œå¼ºçƒˆå»ºè®®ä¸“å®¶å¤å®¡"
        
        processing_time = time.time() - start_time
        
        response_data = {
            'success': True,
            'type': verification_type,
            'algorithm': algorithm_used,
            'similarity': round(similarity, 4),
            'euclidean_distance': round(euclidean_distance, 4) if euclidean_distance is not None else None,
            'ssim': round(result['ssim'], 4) if verification_type == "signature" and result is not None and result.get('ssim') is not None else None,
            'signet_pipeline': result.get('pipeline') if verification_type == "signature" and result is not None else None,
            'final_score': round(final_score, 4),
            'confidence': confidence,
            'is_authentic': final_score > threshold and confidence != 'low',
            'threshold': threshold,
            'recommendation': recommendation,
            'processing_time_ms': round(processing_time * 1000, 2),
            'clean_enabled': enable_clean if verification_type == "signature" else None,
            'clean_mode': clean_mode if verification_type == "signature" and enable_clean else None,
            # GNNç‰¹æœ‰ä¿¡æ¯
            'gnn_keypoints_template': gnn_info.get('keypoints_template') if gnn_info else None,
            'gnn_keypoints_query': gnn_info.get('keypoints_query') if gnn_info else None,
            'gnn_distance': gnn_info.get('gnn_distance') if gnn_info else None
        }
        
        # æ·»åŠ è°ƒè¯•å›¾åƒè·¯å¾„ï¼ˆå¦‚æœæœ‰ï¼‰
        if verification_type == "signature" and result is not None and 'debug_images' in result:
            response_data['debug_images'] = result['debug_images']
        
        return response_data
        
    except Exception as e:
        import traceback
        return JSONResponse(
            status_code=500,
            content={
                'success': False,
                'error': str(e),
                'traceback': traceback.format_exc()
            }
        )

# æŒ‚è½½å‰ç«¯é™æ€æ–‡ä»¶ (ç”¨äºå•å®¹å™¨éƒ¨ç½²)
# æ³¨æ„: é™æ€æ–‡ä»¶è·¯ç”±å¿…é¡»æ”¾åœ¨æœ€å,é¿å…è¦†ç›–APIè·¯ç”±
frontend_path = os.path.join(os.path.dirname(__file__), "..", "frontend")
if os.path.exists(frontend_path):
    app.mount("/", StaticFiles(directory=frontend_path, html=True), name="static")
    print(f"âœ… å‰ç«¯é™æ€æ–‡ä»¶å·²æŒ‚è½½: {frontend_path}")
else:
    print(f"âš ï¸ å‰ç«¯ç›®å½•ä¸å­˜åœ¨: {frontend_path}")

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ å¯åŠ¨æœåŠ¡å™¨: http://localhost:8000")
    print("ğŸ“– APIæ–‡æ¡£: http://localhost:8000/docs")
    print("ğŸ¨ å‰ç«¯ç•Œé¢: http://localhost:8000")
    uvicorn.run(app, host="0.0.0.0", port=8000)
