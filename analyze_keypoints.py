#!/usr/bin/env python3
"""
å…³é”®ç‚¹æ ‡æ³¨æ•°æ®ç¤ºä¾‹åˆ†æ
å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ ‡æ³¨çš„å…³é”®ç‚¹æ•°æ®
"""

import json
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
from collections import Counter


def load_keypoint_data(json_path):
    """åŠ è½½å…³é”®ç‚¹æ ‡æ³¨æ•°æ®"""
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data


def visualize_keypoint_distribution(data):
    """å¯è§†åŒ–å…³é”®ç‚¹åˆ†å¸ƒ"""
    keypoints = data['keypoints']
    width = data['image_size']['width']
    height = data['image_size']['height']
    
    # æŒ‰ç±»å‹åˆ†ç»„
    type_groups = {
        'endpoint': [],
        'junction': [],
        'corner': [],
        'bifurcation': []
    }
    
    for kp in keypoints:
        kp_type = kp['type']
        if kp_type in type_groups:
            type_groups[kp_type].append((kp['x'], kp['y']))
    
    # ç»˜å›¾
    plt.figure(figsize=(10, 8))
    
    colors = {
        'endpoint': 'red',
        'junction': 'green',
        'corner': 'blue',
        'bifurcation': 'cyan'
    }
    
    labels = {
        'endpoint': 'ç«¯ç‚¹',
        'junction': 'äº¤å‰ç‚¹',
        'corner': 'è½¬æŠ˜ç‚¹',
        'bifurcation': 'åˆ†å‰ç‚¹'
    }
    
    for kp_type, points in type_groups.items():
        if points:
            xs, ys = zip(*points)
            plt.scatter(xs, ys, c=colors[kp_type], s=100, 
                       label=f"{labels[kp_type]} ({len(points)})",
                       alpha=0.7, edgecolors='black', linewidth=1.5)
    
    plt.xlim(0, width)
    plt.ylim(height, 0)  # Yè½´åè½¬(å›¾åƒåæ ‡ç³»)
    plt.xlabel('Xåæ ‡', fontsize=12)
    plt.ylabel('Yåæ ‡', fontsize=12)
    plt.title('ç­¾åå…³é”®ç‚¹åˆ†å¸ƒå›¾', fontsize=14, fontweight='bold')
    plt.legend(loc='best', fontsize=10)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    output_path = 'keypoint_distribution.png'
    plt.savefig(output_path, dpi=150)
    print(f"âœ… åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°: {output_path}")
    plt.close()


def compute_graph_edges(keypoints, max_distance=50):
    """
    æ ¹æ®å…³é”®ç‚¹è®¡ç®—å›¾çš„è¾¹
    è¿æ¥è·ç¦»å°äºmax_distanceçš„å…³é”®ç‚¹å¯¹
    """
    edges = []
    n = len(keypoints)
    
    for i in range(n):
        for j in range(i+1, n):
            x1, y1 = keypoints[i]['x'], keypoints[i]['y']
            x2, y2 = keypoints[j]['x'], keypoints[j]['y']
            
            dist = np.sqrt((x1-x2)**2 + (y1-y2)**2)
            
            if dist <= max_distance:
                edges.append((i, j))
    
    return edges


def extract_node_features(keypoints, width, height):
    """
    æå–èŠ‚ç‚¹ç‰¹å¾å‘é‡
    ç‰¹å¾: [å½’ä¸€åŒ–x, å½’ä¸€åŒ–y, ç±»å‹one-hot(4ç»´)]
    """
    type_to_idx = {
        'endpoint': 0,
        'junction': 1,
        'corner': 2,
        'bifurcation': 3
    }
    
    features = []
    for kp in keypoints:
        # ä½ç½®ç‰¹å¾(å½’ä¸€åŒ–)
        x_norm = kp['x'] / width
        y_norm = kp['y'] / height
        
        # ç±»å‹ç‰¹å¾(one-hot)
        type_onehot = [0, 0, 0, 0]
        type_idx = type_to_idx.get(kp['type'], 0)
        type_onehot[type_idx] = 1
        
        # åˆå¹¶ç‰¹å¾
        feat = [x_norm, y_norm] + type_onehot
        features.append(feat)
    
    return np.array(features, dtype=np.float32)


def compute_graph_statistics(keypoints, edges):
    """è®¡ç®—å›¾çš„ç»Ÿè®¡ç‰¹å¾"""
    n_nodes = len(keypoints)
    n_edges = len(edges)
    
    # åº¦åˆ†å¸ƒ
    degree = [0] * n_nodes
    for i, j in edges:
        degree[i] += 1
        degree[j] += 1
    
    avg_degree = np.mean(degree)
    max_degree = np.max(degree)
    
    # ç±»å‹åˆ†å¸ƒ
    type_counts = Counter([kp['type'] for kp in keypoints])
    
    print("\nğŸ“Š å›¾ç»“æ„ç»Ÿè®¡:")
    print(f"   èŠ‚ç‚¹æ•°: {n_nodes}")
    print(f"   è¾¹æ•°: {n_edges}")
    print(f"   å¹³å‡åº¦: {avg_degree:.2f}")
    print(f"   æœ€å¤§åº¦: {max_degree}")
    print(f"   å›¾å¯†åº¦: {2*n_edges/(n_nodes*(n_nodes-1)) if n_nodes > 1 else 0:.4f}")
    
    print("\nğŸ“Š å…³é”®ç‚¹ç±»å‹åˆ†å¸ƒ:")
    type_labels = {
        'endpoint': 'ç«¯ç‚¹',
        'junction': 'äº¤å‰ç‚¹',
        'corner': 'è½¬æŠ˜ç‚¹',
        'bifurcation': 'åˆ†å‰ç‚¹'
    }
    for kp_type, count in type_counts.items():
        label = type_labels.get(kp_type, kp_type)
        print(f"   {label}: {count} ({count/n_nodes*100:.1f}%)")


def compare_two_signatures(data1, data2):
    """
    æ¯”è¾ƒä¸¤ä¸ªç­¾åçš„å…³é”®ç‚¹ç»“æ„
    ç®€å•ç¤ºä¾‹:æ¯”è¾ƒå…³é”®ç‚¹æ•°é‡å’Œç±»å‹åˆ†å¸ƒ
    """
    print("\nğŸ” ç­¾åå¯¹æ¯”åˆ†æ:")
    print("="*50)
    
    # æå–ç»Ÿè®¡ä¿¡æ¯
    stats1 = data1['statistics']
    stats2 = data2['statistics']
    
    total1 = sum(stats1.values())
    total2 = sum(stats2.values())
    
    print(f"ç­¾å1æ€»å…³é”®ç‚¹æ•°: {total1}")
    print(f"ç­¾å2æ€»å…³é”®ç‚¹æ•°: {total2}")
    print(f"æ•°é‡å·®å¼‚: {abs(total1 - total2)} ({abs(total1-total2)/max(total1,total2)*100:.1f}%)")
    
    # ç±»å‹åˆ†å¸ƒç›¸ä¼¼åº¦
    type_labels = {
        'endpoint': 'ç«¯ç‚¹',
        'junction': 'äº¤å‰ç‚¹',
        'corner': 'è½¬æŠ˜ç‚¹',
        'bifurcation': 'åˆ†å‰ç‚¹'
    }
    
    print("\nç±»å‹åˆ†å¸ƒå¯¹æ¯”:")
    similarity_scores = []
    for kp_type in type_labels.keys():
        count1 = stats1.get(kp_type, 0)
        count2 = stats2.get(kp_type, 0)
        
        # å½’ä¸€åŒ–
        ratio1 = count1 / total1 if total1 > 0 else 0
        ratio2 = count2 / total2 if total2 > 0 else 0
        
        # ç›¸ä¼¼åº¦(1 - å·®å¼‚)
        sim = 1 - abs(ratio1 - ratio2)
        similarity_scores.append(sim)
        
        print(f"   {type_labels[kp_type]:6s}: {count1:3d} vs {count2:3d} "
              f"(ç›¸ä¼¼åº¦: {sim:.2f})")
    
    overall_sim = np.mean(similarity_scores)
    print(f"\næ•´ä½“ç»“æ„ç›¸ä¼¼åº¦: {overall_sim:.2f}")
    
    if overall_sim > 0.8:
        print("âœ… ç»“è®º: ä¸¤ä¸ªç­¾åç»“æ„éå¸¸ç›¸ä¼¼")
    elif overall_sim > 0.6:
        print("âš ï¸  ç»“è®º: ä¸¤ä¸ªç­¾åç»“æ„æœ‰ä¸€å®šç›¸ä¼¼æ€§")
    else:
        print("âŒ ç»“è®º: ä¸¤ä¸ªç­¾åç»“æ„å·®å¼‚è¾ƒå¤§")
    
    return overall_sim


def export_for_gnn_training(data, output_path='graph_data.npz'):
    """
    å¯¼å‡ºä¸ºGNNè®­ç»ƒæ ¼å¼
    PyTorch Geometricå…¼å®¹æ ¼å¼
    """
    keypoints = data['keypoints']
    width = data['image_size']['width']
    height = data['image_size']['height']
    
    # èŠ‚ç‚¹ç‰¹å¾
    node_features = extract_node_features(keypoints, width, height)
    
    # è¾¹
    edges = compute_graph_edges(keypoints, max_distance=50)
    edge_index = np.array(edges, dtype=np.int64).T  # [2, num_edges]
    
    # ä¿å­˜
    np.savez(output_path,
             node_features=node_features,
             edge_index=edge_index,
             num_nodes=len(keypoints))
    
    print(f"\nğŸ’¾ GNNè®­ç»ƒæ•°æ®å·²å¯¼å‡ºåˆ°: {output_path}")
    print(f"   èŠ‚ç‚¹ç‰¹å¾å½¢çŠ¶: {node_features.shape}")
    print(f"   è¾¹ç´¢å¼•å½¢çŠ¶: {edge_index.shape}")
    
    return output_path


if __name__ == '__main__':
    import sys
    
    print("="*60)
    print("ğŸ” å…³é”®ç‚¹æ ‡æ³¨æ•°æ®åˆ†æå·¥å…·")
    print("="*60)
    
    if len(sys.argv) < 2:
        print("\nç”¨æ³•:")
        print("  å•ä¸ªåˆ†æ: python analyze_keypoints.py <keypoint_json>")
        print("  å¯¹æ¯”åˆ†æ: python analyze_keypoints.py <json1> <json2>")
        print("\nç¤ºä¾‹:")
        print("  python analyze_keypoints.py keypoints_template_20251029_150000.json")
        sys.exit(1)
    
    # åŠ è½½ç¬¬ä¸€ä¸ªç­¾å
    json_path1 = sys.argv[1]
    print(f"\nğŸ“‚ åŠ è½½ç­¾å1: {json_path1}")
    data1 = load_keypoint_data(json_path1)
    
    print(f"   å›¾åƒå°ºå¯¸: {data1['image_size']['width']} x {data1['image_size']['height']}")
    print(f"   å…³é”®ç‚¹æ•°: {len(data1['keypoints'])}")
    
    # å¯è§†åŒ–
    visualize_keypoint_distribution(data1)
    
    # è®¡ç®—å›¾ç»“æ„
    edges1 = compute_graph_edges(data1['keypoints'])
    compute_graph_statistics(data1['keypoints'], edges1)
    
    # å¯¼å‡ºGNNæ ¼å¼
    export_for_gnn_training(data1, 'signature1_graph.npz')
    
    # å¦‚æœæä¾›äº†ç¬¬äºŒä¸ªç­¾å,è¿›è¡Œå¯¹æ¯”
    if len(sys.argv) >= 3:
        json_path2 = sys.argv[2]
        print(f"\nğŸ“‚ åŠ è½½ç­¾å2: {json_path2}")
        data2 = load_keypoint_data(json_path2)
        
        print(f"   å›¾åƒå°ºå¯¸: {data2['image_size']['width']} x {data2['image_size']['height']}")
        print(f"   å…³é”®ç‚¹æ•°: {len(data2['keypoints'])}")
        
        # å¯¹æ¯”åˆ†æ
        compare_two_signatures(data1, data2)
    
    print("\n" + "="*60)
    print("âœ… åˆ†æå®Œæˆ!")
    print("="*60 + "\n")
